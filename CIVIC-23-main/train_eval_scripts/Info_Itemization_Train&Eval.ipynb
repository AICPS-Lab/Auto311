{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "27Mx3uGbzsRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj-UxkxVwCrK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertModel, DistilBertForQuestionAnswering\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad')"
      ],
      "metadata": {
        "id": "00tfYXlYwXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wpJ5QvKJwe-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_excel(\"/content/drive/MyDrive/CIVIC-2023/Copy of 534 Updated_Dataset.xlsx\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "j_tTCqSUwk7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = dataset[\"context\"].tolist()\n",
        "questions = dataset[\"question\"].tolist()\n",
        "answers = dataset[\"answer_text\"].tolist()\n",
        "answers_start = dataset[\"answer_start\"].tolist()\n",
        "answers_end = dataset[\"answer_end\"].tolist()"
      ],
      "metadata": {
        "id": "cNZZkBjfxiB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_answers = []\n",
        "for a, s, e in zip(answers, answers_start, answers_end):\n",
        "    temp = {\n",
        "        \"text\":a,\n",
        "        \"answer_start\":s,\n",
        "        \"answer_end\":e\n",
        "    }\n",
        "    qa_answers.append(temp)"
      ],
      "metadata": {
        "id": "m804bFS6xnUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_map = {\n",
        "    \"Q1\":[],\n",
        "    \"Q2\":[],\n",
        "    \"Q3\":[],\n",
        "    \"Q6\":[],\n",
        "    \"Q7\":[],\n",
        "    \"Q8\":[]\n",
        "}"
      ],
      "metadata": {
        "id": "WOp9b-Jqxqu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_questions(question_num, question_str):\n",
        "  if question_str not in question_map[question_num]:\n",
        "    question_map[question_num].append(question_str)\n",
        "\n",
        "add_questions(\"Q1\", \"What is your name?\")\n",
        "add_questions(\"Q1\", \"Can I have your name please?\")\n",
        "add_questions(\"Q1\", \"What is your name please?\")\n",
        "add_questions(\"Q1\", \"Your name please?\")\n",
        "add_questions(\"Q1\", \"Tell me your name.\")\n",
        "add_questions(\"Q1\", \"Name?\")\n",
        "\n",
        "add_questions(\"Q2\", \"What is the address of your emergency?\")\n",
        "add_questions(\"Q2\", \"What is the address of the emergency?\")\n",
        "add_questions(\"Q2\", \"Can I have the emergency address please?\")\n",
        "add_questions(\"Q2\", \"Tell me the address.\")\n",
        "add_questions(\"Q2\", \"Where did the emergency happen?\")\n",
        "\n",
        "add_questions(\"Q3\", \"What is your phone number?\")\n",
        "add_questions(\"Q3\", \"What is the best phone number for you?\")\n",
        "add_questions(\"Q3\", \"What is your contact number?\")\n",
        "\n",
        "add_questions(\"Q6\", \"What is the suspect description?\")\n",
        "add_questions(\"Q6\", \"What does the suspect look like?\")\n",
        "add_questions(\"Q6\", \"What is the suspect wearing?\")\n",
        "add_questions(\"Q6\", \"Can you give more details about the suspect?\")\n",
        "add_questions(\"Q6\", \"How would you describe the suspect?\")\n",
        "\n",
        "add_questions(\"Q7\", \"What is the vehicle description?\")\n",
        "add_questions(\"Q7\", \"What does the car look like?\")\n",
        "add_questions(\"Q7\", \"Can you offer more details about the vehicle?\")\n",
        "add_questions(\"Q7\", \"How would you describe the vehicle?\")\n",
        "\n",
        "add_questions(\"Q8\", \"What is the property description?\")\n",
        "add_questions(\"Q8\", \"How would you describe the property?\")\n",
        "add_questions(\"Q8\", \"What is the property?\")\n",
        "\n",
        "question_map"
      ],
      "metadata": {
        "id": "pdOBDvW7xvHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "qa_questions = []\n",
        "qa_contexts = contexts\n",
        "for qt in questions:\n",
        "  if qt in question_map.keys():\n",
        "    qa_questions.append(random.choice(question_map[qt]))\n",
        "  else:\n",
        "    qa_questions.append(qt)"
      ],
      "metadata": {
        "id": "3uBetBASx1JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(qa_contexts, qa_questions, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "bEA2NXxex3Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, int(answers[i]['answer_start'])))\n",
        "    end_positions.append(encodings.char_to_token(i, int(answers[i]['answer_end'] - 1)))\n",
        "\n",
        "    # if start position is None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "      start_positions[-1] = tokenizer.model_max_length\n",
        "    if end_positions[-1] is None:\n",
        "      end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, qa_answers)"
      ],
      "metadata": {
        "id": "m2oXNx4MyGgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "5MHIe_VoyQm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "WwkoZ9H4ySfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SQuAD_Dataset(train_encodings)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "KkC5xD1NyUrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on the available device - use GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Working on {device}')"
      ],
      "metadata": {
        "id": "ZZ4DUZZqyrwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "N_EPOCHS = 3\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  loop = tqdm(train_loader, leave=True)\n",
        "  for batch in loop:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch+1}')\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "\n",
        "torch.save(model, \"model.pth\")"
      ],
      "metadata": {
        "id": "KbCABkSHyiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confidence Score"
      ],
      "metadata": {
        "id": "58fnRMcLwp1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/LIAAD/yake"
      ],
      "metadata": {
        "id": "rV7McPhbwlRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "07INPrhHwpKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(context, question):\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    answer_start = torch.argmax(outputs[0])\n",
        "    answer_end = torch.argmax(outputs[1]) + 1\n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(\n",
        "        tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end].cpu()))\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "Tt9cvS6PxcGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "from collections import Counter\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def obtain_conf_scores(inputs, num_runs=5):\n",
        "    alpha = 0.2\n",
        "    kw_extractor = yake.KeywordExtractor()\n",
        "    st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = []\n",
        "    keywords_list = []\n",
        "\n",
        "    for _ in range(num_runs):\n",
        "        with torch.no_grad():\n",
        "            question = inputs[0]\n",
        "            context = inputs[1]\n",
        "            prediction = get_prediction(context, question)\n",
        "\n",
        "            # Extract 5 keywords\n",
        "            predicted_keywords = [kw[0] for kw in kw_extractor.extract_keywords(prediction)[:5]]\n",
        "            keywords_list.append(predicted_keywords)\n",
        "\n",
        "            # Compute sentence embeddings\n",
        "            predicted_embedding = st_model.encode([prediction], convert_to_tensor=True)\n",
        "            embeddings.append(predicted_embedding.cpu().numpy())\n",
        "\n",
        "    # Compute average semantic similarity\n",
        "    avg_semantic_similarity = np.mean(cosine_similarity(np.array(embeddings).squeeze()))\n",
        "\n",
        "    # Compute keyword consistency\n",
        "    common_keywords_ratios = []\n",
        "    for i in range(1, num_runs):\n",
        "        if keywords_list[i] and keywords_list[0]:  # if both are not empty\n",
        "            common_keywords_ratio = len(set(keywords_list[i]) & set(keywords_list[0])) / max(\n",
        "                len(set(keywords_list[0])), 1)\n",
        "        else:  # if either or both are empty\n",
        "            common_keywords_ratio = int(keywords_list[i] == keywords_list[0])  # 1 if both are empty, 0 otherwise\n",
        "\n",
        "        common_keywords_ratios.append(common_keywords_ratio)\n",
        "\n",
        "    avg_common_keywords_ratio = sum(common_keywords_ratios) / num_runs\n",
        "\n",
        "    final_conf_score = alpha * avg_common_keywords_ratio + (1 - alpha) * avg_semantic_similarity\n",
        "\n",
        "    return final_conf_score"
      ],
      "metadata": {
        "id": "Nh4Jk6YTwvjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}